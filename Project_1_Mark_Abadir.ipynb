{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Project 1 Mark Abadir.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6_ir3o78v-o"
      },
      "source": [
        "# P1: Solve the OpenAI Gym [Taxi V3](https://gym.openai.com/envs/Taxi-v3/) Environment\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8pMVQUY8v-1"
      },
      "source": [
        "## Introduction\n",
        "[OpenAI Gym](https://gym.openai.com/docs/) is a framework that provides RL environments of varying complexity with the same standard API making it easy to develop and benchmark RL algorithms. The [Taxi-V3](https://gym.openai.com/envs/Taxi-v3/) environmnet present a simple, text environment where actions and state (observations) are both discrete. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofm0YBmj8v-3"
      },
      "source": [
        "import gym"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbsI3Ca_8v-5"
      },
      "source": [
        "The `gym.make()` API can be used to spawn any of the available environments by passing its full name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDVkavim8v-6"
      },
      "source": [
        "taxi = gym.make('Taxi-v3')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ3CgugI8v-8"
      },
      "source": [
        "The Taxi environment has 500 states and 6 possible actions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVxUkugW8v-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e690a8-a573-4957-c4e3-807ec2122d90"
      },
      "source": [
        "taxi.action_space"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEgfQ1HM8v-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5661d76-cff7-42eb-c2e8-84f1f5db3ae9"
      },
      "source": [
        "taxi.observation_space"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_3jabLe8v_A"
      },
      "source": [
        "The task and reward structure are described in the [documentation](https://github.com/openai/gym/blob/a5a6ae6bc0a5cfc0ff1ce9be723d59593c165022/gym/envs/toy_text/taxi.py#L25)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GxWMIKK8v_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aeef20a-ef57-4da2-bb04-53fb62eadc03"
      },
      "source": [
        "taxi.reset()\n",
        "taxi.render()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[34;1mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| : |\u001b[43mB\u001b[0m: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFs1-vrM8v_C"
      },
      "source": [
        "## Submission\n",
        "- Submit your solution as a Jupyter notebook. \n",
        "- Ensure that all cells in the notebook have been executed and the output is showing\n",
        "- Ensure that your solution consistently reaches the average cumulative reward defined in the rubric (link below)\n",
        "- Post your solution on Github and share the link to your commit as a direct message in Slack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOarXL1V8v_F"
      },
      "source": [
        "## Evaluation\n",
        "The goal of the project is to get a certain average (cumulative) reward over 100 episodes. To pass the project, you must meet all the requirments in the project [rubric](https://github.com/KnowchowHQ/rl-in-action/blob/master/C1-RL-Intro/W3OH/P1-rubric.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hVFzyBHSKM0"
      },
      "source": [
        "# Part 1\n",
        "\n",
        "The methods are as follows:\n",
        "* `seed()`: generate a seeded random number generator.\n",
        "* `reset()`: reset the environment (randomly select new starting state and reset `lastaction` variable\n",
        "* `step(action)`: take a step with an action to advance the state\n",
        "\n",
        "Variables:\n",
        "* `isd`: distribution modelling the probabilities of a certain initial state\n",
        "* `lastaction`: the previous executed action\n",
        "* `nS`: Number of states\n",
        "* `nA`: Number of actions\n",
        "* `action_space`: object with all possible actions\n",
        "* `observation_space`: object with all possible states\n",
        "* `s`: current state\n",
        "\n",
        "# Part 2\n",
        "\n",
        "Methods:\n",
        "* `encode(row, col, pass_loc, dest_idx)`: Convert the 4-tuple state into a single integer\n",
        "* `decode(i)`: Convert a state integer into a 4-tuple\n",
        "* `render()`: Render the state by printing it out\n",
        "\n",
        "Variables:\n",
        "* `locs`: locations of possible pickup and drop off places\n",
        "* `num_states`: number of states\n",
        "* `num_rows, num_columns`: dimensions of the board\n",
        "* `max_row, max_col`: max index of each dimension\n",
        "* `initial_state_distrib`: like isd above\n",
        "* `num_actions`: number of actions\n",
        "\n",
        "# Part 3\n",
        "\n",
        "The environment is a 5x5 grid of locations the taxi can occupy. 4 of these locations are possible pickup and dropoff locations (labeled R, G, B, and Y). The passenger can exist at any one of these 4 locations or in the taxi.\n",
        "\n",
        "The taxi has 6 actions\n",
        "* Move in a cardinal direction\n",
        "* Pick up the passenger\n",
        "* Drop off the passenger\n",
        "\n",
        "The state contains all necessary information. That is, the posiiton of the taxi, the location of the passenger in one of its valid positions (R, G, B, Y, taxi), and the destination (R, G, B or Y)\n",
        "\n",
        "The rewards are as follows\n",
        "* Each step is -1, to encourage short trips\n",
        "* A valid drop off is +20, to encourage the agent to make the drop off\n",
        "* An invalid pickup or drop off is -10, to discourage misused pickup and drop off actions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pr6w864Mv-q"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJuT-20oFbKK"
      },
      "source": [
        "def epsilon_greedy_action_from_Q(Q, state, epsilon):\n",
        "  actions = Q.columns\n",
        "  greedy_action = np.argmax(Q.loc[state].values)\n",
        "\n",
        "  action_probs = np.asarray([epsilon/len(actions)]*len(actions), dtype=np.float)\n",
        "  action_probs[greedy_action] += 1 - epsilon\n",
        "\n",
        "  epsilon_greedy_choice = np.random.choice(Q.columns, p=action_probs)\n",
        "\n",
        "  return epsilon_greedy_choice\n",
        "\n",
        "def run_sarsa(hyper_params):\n",
        "  Q = pd.DataFrame.from_dict({s:{a: 0 for a in range(taxi.action_space.n)} for s in range(taxi.observation_space.n)}, orient=\"index\")\n",
        "\n",
        "  epsilon = hyper_params[\"epsilon_init\"]\n",
        "  rewards = np.zeros(hyper_params[\"num_episodes\"])\n",
        "  illegal_action_episodes = set()\n",
        "\n",
        "  for ep_num in tqdm(range(hyper_params[\"num_episodes\"]), position=0, leave=True):\n",
        "    s0 = taxi.reset()\n",
        "    a0 = epsilon_greedy_action_from_Q(Q, s0, epsilon)\n",
        "    done = False\n",
        "\n",
        "    episode_reward = 0\n",
        "    while True:\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "      s1, reward, done, _ = taxi.step(a0)\n",
        "      a1 = epsilon_greedy_action_from_Q(Q, s1, epsilon)\n",
        "\n",
        "      Q.loc[s0, a0] += \\\n",
        "      hyper_params[\"alpha\"]*(reward + hyper_params[\"gamma\"]*Q.loc[s1, a1] - Q.loc[s0, a0])\n",
        "\n",
        "      s0, a0 = s1, a1\n",
        "      episode_reward += reward\n",
        "\n",
        "      if ep_num >= hyper_params[\"num_episodes\"] - 1000 and reward == -10:\n",
        "        illegal_action_episodes.add(ep_num)\n",
        "\n",
        "    rewards[ep_num] = episode_reward\n",
        "    if ep_num > hyper_params[\"epsilon_decay_delay\"]:\n",
        "      epsilon = max(epsilon*hyper_params[\"epsilon_decay\"], hyper_params[\"epsilon_min\"])\n",
        "  \n",
        "  print(\"Illegal pickups/dropoffs occurred in \" + str(len(illegal_action_episodes)) + \" of the last 1000 episodes\")\n",
        "  return Q, rewards\n",
        "\n",
        "def read_rewards(rewards):\n",
        "  windowed_rewards = np.convolve(rewards, np.ones(100)/100, 'valid')\n",
        "  last_1000 = windowed_rewards[-900:]\n",
        "  \n",
        "  print()\n",
        "  print(\"50th percentile: \" + str(np.percentile(last_1000, 50)))\n",
        "  print(\"95th percentile: \" + str(np.percentile(last_1000, 95)))\n",
        "\n",
        "  plt.plot(windowed_rewards)\n",
        "  plt.xlabel(\"episode\")\n",
        "  plt.ylabel(\"reward\")\n",
        "  plt.show()\n",
        "\n",
        "def display_episode(Q):\n",
        "  for _ in range(50):\n",
        "    s = taxi.reset()\n",
        "    a = epsilon_greedy_action_from_Q(Q, s, 0)\n",
        "    s, _, done, _ = taxi.step(a)\n",
        "\n",
        "    taxi.render()\n",
        "\n",
        "    if done:\n",
        "      break"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw3BgRGo77MC"
      },
      "source": [
        "# Parts 4, 5, and 6\n",
        "\n",
        "My results for various sets of hyper parameters can be seen in the table below. To test them for yourself, you can call `run_sarsa(h)` where `h` is one of the hyper params dicts defined in the cell below.\n",
        "\n",
        "| hyper_parameter_set | 50th percentile | 95th percentile |\n",
        "|---------------------|-----------------|-----------------|\n",
        "| `hyper_params_1`    | -5.2            | -2.7            |\n",
        "| `hyper_params_2`    | 5.19            | 6.31            |\n",
        "| `hyper_params_3`    | 8.06            | 8.42            |\n",
        "\n",
        "My fixed hyper parameter choices\n",
        "\n",
        "1. `num_episodes`: Will be no greater than 10000 for the sake of time efficiency\n",
        "2. `epsilon_init`: Will be set to 1 initially, for completely random episodes at the beginning of SARSA. Will not change.\n",
        "3. maximum episode length: There is no max episode length as I want the reward for a successful dropoff factored in at each episode \n",
        "\n",
        "I decided to start at the following hyper params for my first test (which can be found in `hyper_params_1`)\n",
        "\n",
        "1. `num_episodes`: 10000, my max, to check if the algorithm will converge\n",
        "2. `epsilon_min`: 0.05, since we want it to decay to almost nothing so as to not explore on the final 1000 episodes\n",
        "3. `epsilon_decay_delay`: 500, to allow for many initial episodes of pure explorations \n",
        "4. `alpha`: 0.01, to make small changes\n",
        "5. `gamma`: 0.99, to moderately discount future returns\n",
        "\n",
        "The results weren't good and my graph of windowed rewards over time didn't show convergence so I decided to make the following changes (found in `hyper_params_2`)\n",
        "\n",
        "1. `alpha`: increased to 0.04. More aggressive changes will be needed for faster convergence. \n",
        "2. `epsilon_decay_delay`: The epochs at the beginning with random exploration seemed to merely delay the start of useful training so I decided to reduce the number of epochs pure exploration epochs to 100.\n",
        "\n",
        "Results improved greatly and the graph converged in 10000 episodes. Though I suspected improved training would come from not discounting further rewards so much. So I made the following changes (found in `hyper_params_3`).\n",
        "\n",
        "1. `gamma`: increased gamma to 0.999, therefore policies that direct towards a correct dropoff would more prominantly emphasize the reward of a correct dropoff\n",
        "2. `epislon_min`: set to 0 since we want virtually no exploration in the final episodes, so as to boost the windowed returns that will be used for results.\n",
        "\n",
        "And as you can see from the table, the 50th precentile and 95th precentile were in range. As well, no illegal dropoffs or pickups were performed in the last 1000 episodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "LoH1WirtF7kW",
        "outputId": "d87c8062-d1e0-4eb0-d8f0-1e97bb88e8b4"
      },
      "source": [
        "hyper_params_1 = {\n",
        "    \"num_episodes\": 10000,\n",
        "    \"epsilon_init\": 1,\n",
        "    \"epsilon_decay\": 0.99,\n",
        "    \"epsilon_decay_delay\": 500,\n",
        "    \"epsilon_min\": 0.05,\n",
        "    \"alpha\": 0.01,\n",
        "    \"gamma\": 0.99\n",
        "}\n",
        "\n",
        "hyper_params_2 = {\n",
        "    \"num_episodes\": 10000,\n",
        "    \"epsilon_init\": 1,\n",
        "    \"epsilon_decay\": 0.99,\n",
        "    \"epsilon_decay_delay\": 100,\n",
        "    \"epsilon_min\": 0.05,\n",
        "    \"alpha\": 0.04,\n",
        "    \"gamma\": 0.99\n",
        "}\n",
        "\n",
        "hyper_params_3 = {\n",
        "    \"num_episodes\": 10000,\n",
        "    \"epsilon_init\": 1,\n",
        "    \"epsilon_decay\": 0.99,\n",
        "    \"epsilon_decay_delay\": 100,\n",
        "    \"epsilon_min\": 0.00,\n",
        "    \"alpha\": 0.04,\n",
        "    \"gamma\": 0.999\n",
        "}\n",
        "\n",
        "Q_final, rewards = run_sarsa(hyper_params_3)\n",
        "read_rewards(rewards)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [03:03<00:00, 54.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Illegal pickups/dropoffs occurred in 0 of the last 1000 episodes\n",
            "\n",
            "50th percentile: 8.06\n",
            "95th percentile: 8.42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}